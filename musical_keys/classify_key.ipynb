{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a neural network that detects the musical key of a piece based on the musical pitches of the notes. All the pieces were taken from midiworld (https://www.midiworld.com/search/?q=POP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from midi_to_csv import convert_data\n",
    "from clean_data import clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure data is properly converted and cleaned.\n",
    "convert_data()\n",
    "clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a neural network with multiple hidden layers and utilize keras's Adam optimzer during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1/1 [==============================] - 0s 237ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 22ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 21ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.6933 - val_loss: nan - val_accuracy: 0.7105\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.7105\n",
      "Test accuracy: 0.7105262875556946\n"
     ]
    }
   ],
   "source": [
    "# Load the dataframe\n",
    "df = pd.read_csv('clean_data/keys.csv')\n",
    "\n",
    "# Split the dataframe into input (notes) and output (musical key) variables\n",
    "X = df.iloc[:, 1:].values  # Notes (numerical representation)\n",
    "y = df.iloc[:, 0].values   # Musical key\n",
    "\n",
    "# Convert the musical key labels to integers from 0 to 23 inclusive\n",
    "key_to_int = {key: i for i, key in enumerate(np.unique(y))}\n",
    "y = np.array([key_to_int[key] for key in y])\n",
    "\n",
    "# Normalize the input data\n",
    "X = X / np.max(X)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=200, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, our model yields an accuracy of 71%. Fiddling with epoch sizes/numbers seems to yield the smae result. This is likely because pieces can often deviate from their musical key, either through modulation or embellishment. Moreover, music from different eras is likely to less/more adhere to traditional musical strcuture. Thus, more accurate models likely need to consider the style and era the music was produced during,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
